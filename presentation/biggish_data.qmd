---
title: "Biggish Data: Tips and tricks for working with kinda big data in R"
author: "Jeff Hollister"
format: 
    pptx:
       reference-doc: template.pptx
editor_options: 
  chunk_output_type: console
---

## Biggish Data 

- Most data not "Big"
- Lot of data "biggish"
  - Storage challenges
  - Read/Write challenges
  - Analysis challenges
- Useful for all datasets
  - Less storage
  - Less CPU time
  - Less bandwidth
  - The "cloud" isn't free.

## Outline

- The examples
- Writing data
- Reading data
- File sizes
- Summarizing data
- S3

## The example - Biggish National Lakes Assessment 2017

```{r make_nla_big, echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(readr)
url <- "https://www.epa.gov/sites/default/files/2021-04/nla_2017_water_chemistry_chla-data.csv"
nla17 <- read_csv(url)
nla_big <- nla17[sample(1:nrow(nla17),10000000,replace=TRUE),]
nla_big <- rename(nla_big, state = STATE, 
                  analyte = ANALYTE, 
                  result = RESULT)
```

## The example - Biggish National Lakes Assessment 2017

```{r how_big, echo=TRUE}
dim(nla_big)
format(object.size(nla_big), "Gb")
```

## Packages

```{r writing_packages, echo = TRUE, message=FALSE, warning=FALSE}
library(data.table)
library(readr)
library(arrow)
library(tictoc) #Timing
```

- [Apache Arrow](https://arrow.apache.org/)
- Language independent file format(s) for columnar datasets
- parquet, geoparquet, feather, Arrow csv

## Writing data

- utils::write.csv (.csv)
- readr::write_csv (.csv)
- data.table::fwrite (.csv)
- arrow::write_csv_arrow (.csv)
- base::save (.rda)
- arrow::write_feather (.feather)
- arrow::write_parquet (.parquet)
- arrow::write_dataset (partions/multiple .parquet)

## Writing data - `utils::write.csv`

```{r base_write, eval = FALSE, echo=TRUE, message=FALSE}
tic()
write.csv(nla_big, "../data/nla_big.csv")
toc()
```

```{r base_write_x, echo=FALSE, cache=TRUE, message=FALSE}
tic()
write.csv(nla_big, "../data/nla_big.csv")
x <- toc() 
compare_df <- tibble(category = "write",
                               variable = "write.csv",
                               value = as.numeric(x$toc - x$tic))
compare_df <- bind_rows(compare_df,
                        tibble(category = "size",
                               variable = "readr::write.csv",
                               value = as.numeric(file.size("../data/nla_big.csv"))))

fs::file_delete("../data/nla_big.csv")
x <- gc()
```

## Writing data - `readr::write_csv`

```{r readr_write, eval=FALSE, echo=TRUE, message=FALSE}
tic()
write_csv(nla_big, "../data/nla_big.csv")
toc()
```

```{r readr_write_x, echo=FALSE, cache=TRUE, message=FALSE}
tic()
write_csv(nla_big, "../data/nla_big.csv")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "write",
                               variable = "write_csv",
                               value = as.numeric(x$toc - x$tic)),
                        tibble(category = "size",
                               variable = "write_csv",
                               value = as.numeric(
                                 file.size("../data/nla_big.csv"))))
fs::file_delete("../data/nla_big.csv")
x <- gc()
```

## Writing data - `data.table::fwrite`

```{r data_table_write, eval = FALSE, echo=TRUE, message=FALSE}
tic()
fwrite(nla_big, "../data/nla_big.csv")
toc()
```

```{r data_table_write_x, echo=FALSE, cache=TRUE, message=FALSE}
tic()
fwrite(nla_big, "../data/nla_big.csv")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "write",
                               variable = "data.table::fwrite",
                               value = as.numeric(x$toc - x$tic)),
                        tibble(category = "size",
                               variable = "data.table::fwrite",
                               value = as.numeric(
                                 file.size("../data/nla_big.csv"))))
fs::file_delete("../data/nla_big.csv")
x <- gc()
```

## Writing data - `arrow::write_csv_arrow`

```{r arrow_write, eval=FALSE, echo=TRUE, message=FALSE}
tic()
write_csv_arrow(nla_big, file = "../data/nla_big.csv")
toc()
```

```{r arrow_write_x, echo=FALSE, cache=TRUE, message=FALSE}
tic()
write_csv_arrow(nla_big, file = "../data/nla_big.csv")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "write",
                               variable = "arrow::write_csv_arrow",
                               value = as.numeric(x$toc - x$tic)),
                        tibble(category = "size",
                               variable = "arrow::write_csv_arrow",
                               value = as.numeric(
                                 file.size("../data/nla_big.csv"))))
x <- gc()
```

## Writing data - `base::save`

```{r base_save, eval=FALSE, echo=TRUE, message=FALSE}
tic()
save(nla_big, file = "../data/nla_big.rda")
toc()
```

```{r base_save_x, echo=FALSE, cache=TRUE, message=FALSE}
tic()
save(nla_big, file = "../data/nla_big.rda")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "write",
                               variable = "base::save",
                               value = as.numeric(x$toc - x$tic)),
                        tibble(category = "size",
                               variable = "base::save",
                               value = as.numeric(
                                 file.size("../data/nla_big.rda"))))
x <- gc()
```

## Writing data - `arrow::write_feather`

```{r arrow_feather, eval=FALSE, echo=TRUE, message=FALSE}
tic()
write_feather(nla_big, sink = "../data/nla_big.feather", 
              compression = "zstd")
toc()
```

```{r arrow_feather_x, echo=FALSE, cache=TRUE, message=FALSE}
tic()
write_feather(nla_big, sink = "../data/nla_big.feather", 
              compression = "zstd")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "write",
                               variable = "arrow::write_feather",
                               value = as.numeric(x$toc - x$tic)),
                        tibble(category = "size",
                               variable = "arrow::write_feather",
                               value = as.numeric(
                                 file.size("../data/nla_big.feather"))))
x <- gc()
```

## Writing data - `arrow::write_parquet`

```{r arrow_parquet, eval=FALSE, echo=TRUE, message=FALSE}
tic()
write_parquet(nla_big, sink = "../data/nla_big.parquet", 
              compression = "zstd")
toc()
```

```{r arrow_parquet_x, echo=FALSE, cache=TRUE, message=FALSE}
tic()
write_parquet(nla_big, sink = "../data/nla_big.parquet", 
              compression = "zstd") 
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "write",
                               variable = "arrow::write_parquet",
                               value = as.numeric(x$toc - x$tic)),
                        tibble(category = "size",
                               variable = "arrow::write_parquet",
                               value = as.numeric(
                                 file.size("../data/nla_big.parquet"))))
x <- gc()
```

## Writing data - `arrow::write_dataset` multiple file format

```{r arrow_parquet_part, eval=FALSE, echo=TRUE, message=FALSE}
tic()
nla_big |> 
  group_by(state) |>
  write_dataset(path = "../data/nla_big", compression = "zstd")
toc()
```

```{r arrow_parquet_part_x, echo=FALSE, cache=TRUE, message=FALSE}
tic()
nla_big |> 
  group_by(state) |>
  write_dataset(path = "../data/nla_big", compression = "zstd")
x <- toc()  
compare_df <- bind_rows(compare_df,
                        tibble(category = "write",
                               variable = "arrow::write_parquet partition",
                               value = as.numeric(x$toc - x$tic)),
                        tibble(category = "size",
                               variable = "arrow::write_parquet 50 partitions",
                               value = as.numeric(
                                 50 * file.size("../data/nla_big/state=CA/part-0.parquet"))))
x <- gc()
```

## Writing data - Times

```{r times_table}
time_df <- compare_df |>
  filter(category == "write") |>
  mutate(time = round(units::set_units(value, "seconds"),1)) |>
  arrange(desc(time)) |>
  select("function" = variable, time)
knitr::kable(time_df)
```

## Writing data - File sizes

```{r size_table}
size_df <- compare_df |>
  filter(category == "size") |>
  mutate(size = round(units::set_units(
    units::set_units(value, "bytes"), "megabytes"),1)) |>
  arrange(desc(size)) |>
  select("function" = variable, size)
knitr::kable(size_df)
```

## Reading data

- utils::read.csv
- readr::read_csv
- data.table::fread
- arrow::read_csv_arrow
- arrow::read_feather
- arrow::read_parquet
- arrow::open_dataset multi-file parquet

## Reading data - utils::read.csv

```{r utils_read.csv, eval=FALSE, echo=TRUE}
tic()
df <- read.csv("../data/nla_big.csv")
toc()
```

```{r utils_read.csv_x, eval=TRUE, cache=TRUE, echo=FALSE, message = FALSE}
tic()
df <- read_csv("../data/nla_big.csv")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "read",
                               variable = "utils::read.csv",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Reading data - readr::read_csv

```{r read_csv, eval=FALSE, echo=TRUE}
tic()
df <- read_csv("../data/nla_big.csv")
toc()
```

```{r read_csv_x, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- read_csv("../data/nla_big.csv")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "read",
                               variable = "readr::read_csv",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Reading data - data.table::fread

```{r fread, eval=FALSE, echo=TRUE}
tic()
df <- fread("../data/nla_big.csv")
toc()
```

```{r fread_x, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- fread("../data/nla_big.csv")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "read",
                               variable = "data.table::fread",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Reading data - arrow::read_csv_arrow

```{r read_csv_arrow, eval=FALSE, cache=TRUE, echo=TRUE}
tic()
df <- read_csv_arrow("../data/nla_big.csv")
toc()
```

```{r read_csv_arrow_x, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- read_csv_arrow("../data/nla_big.csv")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "read",
                               variable = "arrow::read_csv_arrow",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Reading data - arrow::read_feather

```{r read_feather, eval=FALSE, cache=TRUE, echo=TRUE}
tic()
df <- read_feather("../data/nla_big.feather")
toc()
```

```{r read_feather_x, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- read_feather("../data/nla_big.feather")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "read",
                               variable = "arrow::read_feather",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Reading data - arrow::read_parquet

```{r read_parquet, eval=FALSE, cache=TRUE, echo=TRUE}
tic()
df <- read_parquet("../data/nla_big.parquet")
toc()

```

```{r read_parquet_x, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- read_parquet("../data/nla_big.parquet")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "read",
                               variable = "arrow::read_parquet",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Reading data - arrow::open_dataset multi-file parquet

```{r open_dataset, eval=FALSE, cache=TRUE, echo=TRUE}
tic()
df <- open_dataset("../data/nla_big")
toc()
```


```{r open_dataset_x, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- open_dataset("../data/nla_big")
x <- toc() 
compare_df <- bind_rows(compare_df,
                        tibble(category = "read",
                               variable = "arrow::open_dataset",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Reading data - Times

```{r read_times}
time_df <- compare_df |>
  filter(category == "read") |>
  mutate(time = round(units::set_units(value, "seconds"),1)) |>
  arrange(desc(time)) |>
  select("function" = variable, time)
knitr::kable(time_df)
```

## Summarizing data

- Take our 10 million rows and
  - group on state and analyte
  - provide state average for each analyte
  - count number of samples per group
  - Result:
    - 4 columns
      - state, analyte, avg_result, group_n
    - 919 rows

## Summarizing data

- readr::read_csv
- data.table::fread
- arrow::read_feather
- arrow::read_parquet
- arrow::open_dataset

## Summarizing data - readr::read_csv

```{r summ_readr_code, , eval=FALSE, echo=TRUE, message=FALSE}
tic()
df <- read_csv("../data/nla_big.csv")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()
toc()
class(df)
```

```{r summ_readr, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- read_csv("../data/nla_big.csv")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()
x <- toc()
class(df)
compare_df <- bind_rows(compare_df,
                        tibble(category = "summarize",
                               variable = "readr::read_csv",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Summarizing data - data.table::fread

```{r summ_fread_code, eval=FALSE, echo=TRUE}
tic()
df <- fread("../data/nla_big.csv")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()
toc()
class(df)
```

```{r summ_data.table , eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- fread("../data/nla_big.csv")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()
x <- toc()
class(df)
compare_df <- bind_rows(compare_df,
                        tibble(category = "summarize",
                               variable = "data.table::fread",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Summarizing data - arrow::read_feather

```{r summ_feather_code, eval=FALSE, echo=TRUE}
tic()
df <- read_feather("../data/nla_big.feather")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()
toc()
class(df)
```

```{r summ_feather, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- read_feather("../data/nla_big.feather")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()
x <- toc()
class(df)
compare_df <- bind_rows(compare_df,
                        tibble(category = "summarize",
                               variable = "arrow::read_feather",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Summarizing data - arrow::read_parquet

```{r summ_parquet_code, , eval=FALSE, echo=TRUE}
tic()
df <- read_parquet("../data/nla_big.parquet")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()
toc()
class(df)
```

```{r summ_parquet, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- read_parquet("../data/nla_big.parquet")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()
x <- toc() 
class(df)
compare_df <- bind_rows(compare_df,
                        tibble(category = "summarize",
                               variable = "arrow::open_dataset",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Summarizing data - arrow::open_dataset parquet multiple partitions

```{r summ_parquet_part_code, , eval=FALSE, echo=TRUE}
tic()
df <- open_dataset("../data/nla_big")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup() |>
  collect()
toc()
class(df)
```

```{r summ_parquet_part, eval=TRUE, cache=TRUE, echo=FALSE, message=FALSE}
tic()
df <- open_dataset("../data/nla_big")
df_f_sum <- df |>
  group_by(state, analyte) |>
  summarize(avg_result = round(mean(result), 2),
            group_n = n()) |>
  ungroup()|>
  collect()
x <- toc()
class(df)
compare_df <- bind_rows(compare_df,
                        tibble(category = "summarize",
                               variable = "arrow::open_dataset multiple partitions",
                               value = as.numeric(x$toc - x$tic)))
rm(df)
x <- gc()
```

## Summarizing data - Times

```{r read_times_summ}
time_df <- compare_df |>
  filter(category == "summarize") |>
  mutate(time = round(units::set_units(value, "seconds"),1)) |>
  arrange(desc(time)) |>
  select("function" = variable, time)
knitr::kable(time_df)
```

## Another example - NYC Taxi on S3

- OK, this might be "big" data...

```{r nyc_taxi_big, cache=TRUE, echo=TRUE}
library(arrow)
bucket <- s3_bucket("voltrondata-labs-datasets", 
                    anonymous = TRUE, 
                    region = 'us-east-2')
tic()
nyc_taxi <- open_dataset(bucket$path("nyc-taxi"))
nrow(nyc_taxi)
toc()
```

## Big Data Summarize - NYC Taxi on S3
```{r nyc_taxi_big2, cache=TRUE, echo=TRUE}
tic()
years <- nyc_taxi |>
  group_by(year) |>
  summarize(n = n()) |>
  collect()
head(years, 2)
toc()
```

## Total time

- Jeff's EISD Laptop: 8 cores, 16GB RAM

```{r}
compare_df |>
  filter(category != "size") |> 
  pull(value) |> 
  sum() |>
  units::set_units("seconds") |>
  units::set_units("minutes") |>
  round(2)
```